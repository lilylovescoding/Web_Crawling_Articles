# Web_Crawling_Project
**This is a mini Web Crawling project, aims to get over hundreds of articles from the website and store these articles in a Microsoft word file**. In this way, the planner can analysis these articles easily and boost their efficiency.
In traditional way, people will choose to store each article and repeat more than 100 times. This project can aquire all these articles in 5 less than minute base on Web Crawler technology.

Project flow:
- Get all links of every page
- Use **Request** to parse the source code
- Use **Regular expression** to extract the title and content information
- Store all the content into a Microsoft word file
